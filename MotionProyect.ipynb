{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from motion_detection_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flow(frame1, frame2):\n",
    "    # convert to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # blurr image\n",
    "    gray1 = cv2.GaussianBlur(gray1, dst=None, ksize=(3,3), sigmaX=5)\n",
    "    gray2 = cv2.GaussianBlur(gray2, dst=None, ksize=(3,3), sigmaX=5)\n",
    "    \n",
    "    '''flow_params = dict(\n",
    "        winSize=(5, 5),\n",
    "        maxLevel=5,\n",
    "        flow=None,\n",
    "        flags=0\n",
    "    )\n",
    "\n",
    "    flow = cv2.calcOpticalFlowDenseRLOF(gray1, gray2, **flow_params)'''\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None,\n",
    "                                        pyr_scale=0.75,\n",
    "                                        levels=3,\n",
    "                                        winsize=7,\n",
    "                                        iterations=3,\n",
    "                                        poly_n=8,\n",
    "                                        poly_sigma=1.2,\n",
    "                                        flags=0)\n",
    "    #print(flow)\n",
    "    return flow\n",
    "\n",
    "\n",
    "def get_flow_viz(flow):\n",
    "    \"\"\" Obtains BGR image to Visualize the Optical Flow \n",
    "        \"\"\"\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    hsv[..., 1] = 255\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang*180/np.pi/2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return rgb\n",
    "\n",
    "def get_motion_mask(flow_mag, motion_thresh=1, kernel=np.ones((7,7))):\n",
    "    \"\"\" Obtains Detection Mask from Optical Flow Magnitude\n",
    "        Inputs:\n",
    "            flow_mag (array) Optical Flow magnitude\n",
    "            motion_thresh - thresold to determine motion\n",
    "            kernel - kernal for Morphological Operations\n",
    "        Outputs:\n",
    "            motion_mask - Binray Motion Mask\n",
    "        \"\"\"\n",
    "    motion_mask = np.uint8(flow_mag > motion_thresh)*255\n",
    "    motion_mask = cv2.erode(motion_mask, kernel, iterations=1)\n",
    "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    \n",
    "    return motion_mask\n",
    "\n",
    "def get_contour_detections_2(fr, mask, ang, angle_thresh=2, thresh=300):\n",
    "    \"\"\" Obtains initial proposed detections from contours discoverd on the\n",
    "        mask. Scores are taken as the bbox area, larger is higher.\n",
    "        Inputs:\n",
    "            mask - thresholded image mask\n",
    "            angle_thresh - threshold for flow angle standard deviation\n",
    "            thresh - threshold for contour size\n",
    "        Outputs:\n",
    "            detectons - array of proposed detection bounding boxes and scores \n",
    "                        [[x1,y1,x2,y2,s]]\n",
    "        \"\"\"\n",
    "    # get mask contours\n",
    "    contours, _ = cv2.findContours(mask, \n",
    "                                   cv2.RETR_EXTERNAL, # cv2.RETR_TREE, \n",
    "                                   cv2.CHAIN_APPROX_TC89_L1)\n",
    "    '''cv2.drawContours(fr, contours, -1, (0, 255, 0), 3) \n",
    "    plt.imshow(cv2.cvtColor(fr, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()'''\n",
    "    temp_mask = np.zeros_like(mask) # used to get flow angle of contours\n",
    "    angle_thresh = angle_thresh*ang.std()\n",
    "    detections = []\n",
    "    for cnt in contours:\n",
    "        # get area of contour\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        area = w*h\n",
    "\n",
    "        # get flow angle inside of contour\n",
    "        cv2.drawContours(temp_mask, [cnt], 0, (255,), -1)\n",
    "        flow_angle = ang[np.nonzero(temp_mask)]\n",
    "\n",
    "        if (area > thresh) and (flow_angle.std() < angle_thresh): # hyperparameter\n",
    "            detections.append([x,y,x+w,y+h, area])\n",
    "\n",
    "    return np.array(detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video procesado y guardado en resultado.mp4.\n"
     ]
    }
   ],
   "source": [
    "def procesar_frames(frame1, frame2):\n",
    "    flow = compute_flow(frame1, frame2)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    #cmap_result = plt.get_cmap('hsv_r')(np.log(mag/mag.max()))\n",
    "    rgb = get_flow_viz(flow)\n",
    "    outGRAD = rgb*50\n",
    "    motion_thresh = np.c_[np.linspace(0.3, 1, frame1.shape[0])].repeat(frame1.shape[1], axis=-1)\n",
    "    mask = get_motion_mask(mag, motion_thresh=motion_thresh)\n",
    "    mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "    detections = get_contour_detections_2(frame2, mask, ang, angle_thresh=2, thresh=400)\n",
    "    bboxes = detections[:, :4]\n",
    "    scores = detections[:, -1]\n",
    "    for box in bboxes:\n",
    "        x1,y1,x2,y2 = box\n",
    "        cv2.rectangle(mask_rgb, (x1,y1), (x2,y2), (255,0,0), 3)\n",
    "    #mask_rgb\n",
    "    nms_bboxes = non_max_suppression(bboxes, scores, threshold=0.4)\n",
    "    mask_rgb_detections = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "    for det in nms_bboxes:\n",
    "        x1, y1, x2, y2 = det\n",
    "        cv2.rectangle(mask_rgb_detections, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "    fr2 = frame2.copy()\n",
    "    draw_bboxes(fr2, nms_bboxes)\n",
    "    return outGRAD,fr2\n",
    "\n",
    "def main(video_path, output_video_path_G, output_video_path_resultado):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Asegúrate de que el video se haya abierto correctamente\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error al abrir el video.\")\n",
    "        return\n",
    "\n",
    "    # Obtiene las propiedades del video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Crea un objeto VideoWriter para guardar el nuevo video\n",
    "    fps_deseado = 0.8\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # or 'H264'\n",
    "    out_G = cv2.VideoWriter(output_video_path_G, fourcc, fps_deseado, (frame_width, frame_height))\n",
    "    out_resultado = cv2.VideoWriter(output_video_path_resultado, fourcc, fps_deseado, (frame_width, frame_height))\n",
    "    # Lee el primer frame\n",
    "    ret, frame1 = cap.read()\n",
    "\n",
    "    # Establece la frecuencia deseada (un frame por segundo)\n",
    "    fps_deseado = 3\n",
    "\n",
    "    while True:\n",
    "        # Lee el siguiente frame\n",
    "        ret, frame2 = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Procesa los frames\n",
    "        resultadoG, resultado = procesar_frames(frame1, frame2)\n",
    "        out_G.write(resultadoG)\n",
    "        # Guarda el resultado en el nuevo video\n",
    "        out_resultado.write(resultado)\n",
    "\n",
    "        # Actualiza el frame1 para el próximo ciclo\n",
    "        frame1 = frame2\n",
    "\n",
    "        # Salta frames para alcanzar la frecuencia deseada\n",
    "        saltos = int(fps / fps_deseado)\n",
    "        for _ in range(saltos - 1):\n",
    "            cap.read()\n",
    "\n",
    "    # Libera los objetos de captura y escritura de video\n",
    "    cap.release()\n",
    "    out_G.release()\n",
    "    out_resultado.release()\n",
    "\n",
    "    print(f\"Video procesado y guardado en {output_video_path}.\")\n",
    "\n",
    "# Ruta del video de entrada\n",
    "video_path = 'tokio.mp4'  # Reemplaza con la ruta de tu video\n",
    "\n",
    "# Ruta del video de salida\n",
    "output_video_path = 'resultado.mp4'\n",
    "output_video_path_Gradient = 'resultadoGradient.mp4'\n",
    "\n",
    "# Llama a la función principal para procesar los frames y guardar el nuevo video\n",
    "main(video_path, output_video_path_Gradient, output_video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
