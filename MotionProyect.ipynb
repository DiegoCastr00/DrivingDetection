{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flow(frame1, frame2):\n",
    "    # convert to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # blurr image\n",
    "    gray1 = cv2.GaussianBlur(gray1, dst=None, ksize=(3,3), sigmaX=5)\n",
    "    gray2 = cv2.GaussianBlur(gray2, dst=None, ksize=(3,3), sigmaX=5)\n",
    "    \n",
    "    '''flow_params = dict(\n",
    "        winSize=(5, 5),\n",
    "        maxLevel=5,\n",
    "        flow=None,\n",
    "        flags=0\n",
    "    )\n",
    "\n",
    "    flow = cv2.calcOpticalFlowDenseRLOF(gray1, gray2, **flow_params)'''\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None,\n",
    "                                        pyr_scale=0.75,\n",
    "                                        levels=3,\n",
    "                                        winsize=7,\n",
    "                                        iterations=3,\n",
    "                                        poly_n=8,\n",
    "                                        poly_sigma=1.2,\n",
    "                                        flags=0)\n",
    "    #print(flow)\n",
    "    return flow\n",
    "\n",
    "\n",
    "def get_flow_viz(flow):\n",
    "    \"\"\" Obtains BGR image to Visualize the Optical Flow \n",
    "        \"\"\"\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    hsv[..., 1] = 255\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang*180/np.pi/2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return rgb\n",
    "\n",
    "def get_motion_mask(flow_mag, motion_thresh=1, kernel=np.ones((7,7))):\n",
    "    \"\"\" Obtains Detection Mask from Optical Flow Magnitude\n",
    "        Inputs:\n",
    "            flow_mag (array) Optical Flow magnitude\n",
    "            motion_thresh - thresold to determine motion\n",
    "            kernel - kernal for Morphological Operations\n",
    "        Outputs:\n",
    "            motion_mask - Binray Motion Mask\n",
    "        \"\"\"\n",
    "    motion_mask = np.uint8(flow_mag > motion_thresh)*255\n",
    "    motion_mask = cv2.erode(motion_mask, kernel, iterations=1)\n",
    "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    \n",
    "    return motion_mask\n",
    "\n",
    "def get_contour_detections_2(fr, mask, ang, angle_thresh=2, thresh=300):\n",
    "    \"\"\" Obtains initial proposed detections from contours discoverd on the\n",
    "        mask. Scores are taken as the bbox area, larger is higher.\n",
    "        Inputs:\n",
    "            mask - thresholded image mask\n",
    "            angle_thresh - threshold for flow angle standard deviation\n",
    "            thresh - threshold for contour size\n",
    "        Outputs:\n",
    "            detectons - array of proposed detection bounding boxes and scores \n",
    "                        [[x1,y1,x2,y2,s]]\n",
    "        \"\"\"\n",
    "    # get mask contours\n",
    "    contours, _ = cv2.findContours(mask, \n",
    "                                   cv2.RETR_EXTERNAL, # cv2.RETR_TREE, \n",
    "                                   cv2.CHAIN_APPROX_TC89_L1)\n",
    "    '''cv2.drawContours(fr, contours, -1, (0, 255, 0), 3) \n",
    "    plt.imshow(cv2.cvtColor(fr, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()'''\n",
    "    temp_mask = np.zeros_like(mask) # used to get flow angle of contours\n",
    "    angle_thresh = angle_thresh*ang.std()\n",
    "    detections = []\n",
    "    for cnt in contours:\n",
    "        # get area of contour\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        area = w*h\n",
    "\n",
    "        # get flow angle inside of contour\n",
    "        cv2.drawContours(temp_mask, [cnt], 0, (255,), -1)\n",
    "        flow_angle = ang[np.nonzero(temp_mask)]\n",
    "\n",
    "        if (area > thresh) and (flow_angle.std() < angle_thresh): # hyperparameter\n",
    "            detections.append([x,y,x+w,y+h, area])\n",
    "\n",
    "    return np.array(detections)\n",
    "\n",
    "def draw_bboxesRecortes(frame, detections, output_folder, count):\n",
    "    for i, det in enumerate(detections):\n",
    "        x1, y1, x2, y2 = det\n",
    "\n",
    "        # Recorta la región del bounding box del frame original\n",
    "        roi = frame[y1:y2, x1:x2].copy()\n",
    "        output_path = os.path.join(output_folder, f\"recorte_{count}_{i}.png\")\n",
    "        cv2.imwrite(output_path, roi)\n",
    "        # Dibuja el bounding box en la región recortada\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 3)\n",
    "        \n",
    "def draw_bboxes(frame, detections):\n",
    "    for det in detections:\n",
    "        x1,y1,x2,y2 = det\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_contained_bboxes(boxes):\n",
    "    \"\"\" Removes all smaller boxes that are contained within larger boxes.\n",
    "        Requires bboxes to be soirted by area (score)\n",
    "        Inputs:\n",
    "            boxes - array bounding boxes sorted (descending) by area \n",
    "                    [[x1,y1,x2,y2]]\n",
    "        Outputs:\n",
    "            keep - indexes of bounding boxes that are not entirely contained \n",
    "                   in another box\n",
    "        \"\"\"\n",
    "    check_array = np.array([True, True, False, False])\n",
    "    keep = list(range(0, len(boxes)))\n",
    "    for i in keep: # range(0, len(bboxes)):\n",
    "        for j in range(0, len(boxes)):\n",
    "            # check if box j is completely contained in box i\n",
    "            if np.all((np.array(boxes[j]) >= np.array(boxes[i])) == check_array):\n",
    "                try:\n",
    "                    keep.remove(j)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "    return keep\n",
    "\n",
    "def non_max_suppression(boxes, scores, threshold=1e-1):\n",
    "    \"\"\"\n",
    "    Perform non-max suppression on a set of bounding boxes \n",
    "    and corresponding scores.\n",
    "    Inputs:\n",
    "        boxes: a list of bounding boxes in the format [xmin, ymin, xmax, ymax]\n",
    "        scores: a list of corresponding scores \n",
    "        threshold: the IoU (intersection-over-union) threshold for merging bboxes\n",
    "    Outputs:\n",
    "        boxes - non-max suppressed boxes\n",
    "    \"\"\"\n",
    "    # Sort the boxes by score in descending order\n",
    "    boxes = boxes[np.argsort(scores)[::-1]]\n",
    "\n",
    "    # remove all contained bounding boxes and get ordered index\n",
    "    order = remove_contained_bboxes(boxes)\n",
    "\n",
    "    keep = []\n",
    "    while order:\n",
    "        i = order.pop(0)\n",
    "        keep.append(i)\n",
    "        for j in order:\n",
    "            # Calculate the IoU between the two boxes\n",
    "            intersection = max(0, min(boxes[i][2], boxes[j][2]) - max(boxes[i][0], boxes[j][0])) * \\\n",
    "                           max(0, min(boxes[i][3], boxes[j][3]) - max(boxes[i][1], boxes[j][1]))\n",
    "            union = (boxes[i][2] - boxes[i][0]) * (boxes[i][3] - boxes[i][1]) + \\\n",
    "                    (boxes[j][2] - boxes[j][0]) * (boxes[j][3] - boxes[j][1]) - intersection\n",
    "            iou = intersection / union\n",
    "\n",
    "            # Remove boxes with IoU greater than the threshold\n",
    "            if iou > threshold:\n",
    "                order.remove(j)\n",
    "                \n",
    "    return boxes[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daphne\\AppData\\Local\\Temp\\ipykernel_14908\\672892232.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "  outGRAD = cv2.applyColorMap(cv2.convertScaleAbs(np.log(mag/mag.max())*200), cv2.COLORMAP_TURBO)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video procesado y guardado en resultadoEsquina.mp4.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def procesar_frames(frame1, frame2, numframes):\n",
    "    fr2 = frame2.copy()\n",
    "    fr2_1 = fr2.copy()\n",
    "    fr2_2 = frame2.copy()\n",
    "    fr1 = frame1.copy()\n",
    "    flow = compute_flow(fr1, fr2)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    #cmap_result = plt.get_cmap('hsv_r')(np.log(mag/mag.max()))\n",
    "    rgb = get_flow_viz(flow)\n",
    "    outGRAD = rgb*50\n",
    "    motion_thresh = np.c_[np.linspace(0.3, 1, frame1.shape[0])].repeat(frame1.shape[1], axis=-1)\n",
    "    mask = get_motion_mask(mag, motion_thresh=motion_thresh)\n",
    "    mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "    detections = get_contour_detections_2(fr2_1, mask, ang, angle_thresh=2, thresh=400)\n",
    "    #print(detections.shape)\n",
    "    bboxes = detections[:, :4]\n",
    "    outGRAD = cv2.applyColorMap(cv2.convertScaleAbs(np.log(mag/mag.max())*200), cv2.COLORMAP_TURBO)\n",
    "    scores = detections[:, -1]\n",
    "    for box in bboxes:\n",
    "        x1,y1,x2,y2 = box\n",
    "        cv2.rectangle(mask_rgb, (x1,y1), (x2,y2), (255,0,0), 3)\n",
    "    #mask_rgb\n",
    "    nms_bboxes = non_max_suppression(bboxes, scores, threshold=0.4)\n",
    "    mask_rgb_detections = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "    for det in nms_bboxes:\n",
    "        x1, y1, x2, y2 = det\n",
    "        cv2.rectangle(mask_rgb_detections, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "    draw_bboxesRecortes(fr2_2, nms_bboxes, 'esquina', numframes)\n",
    "    return outGRAD,fr2_2\n",
    "\n",
    "def main(video_path, output_video_path_G, output_video_path_resultado):\n",
    "    numframes = 0\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Asegúrate de que el video se haya abierto correctamente\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error al abrir el video.\")\n",
    "        return\n",
    "\n",
    "    # Obtiene las propiedades del video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Crea un objeto VideoWriter para guardar el nuevo video\n",
    "    fps_deseado = 0.8\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # or 'H264'\n",
    "    out_G = cv2.VideoWriter(output_video_path_G, fourcc, fps_deseado, (frame_width, frame_height))\n",
    "    out_resultado = cv2.VideoWriter(output_video_path_resultado, fourcc, fps_deseado, (frame_width, frame_height))\n",
    "    # Lee el primer frame\n",
    "    ret, frame1 = cap.read()\n",
    "\n",
    "    # Establece la frecuencia deseada (un frame por segundo)\n",
    "    fps_deseado = 1\n",
    "\n",
    "    while True:\n",
    "        # Lee el siguiente frame\n",
    "        ret, frame2 = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Procesa los frames\n",
    "        resultadoG, resultado = procesar_frames(frame1, frame2, numframes)\n",
    "        numframes = numframes +1\n",
    "        out_G.write(resultadoG)\n",
    "        # Guarda el resultado en el nuevo video\n",
    "        out_resultado.write(resultado)\n",
    "        \n",
    "        # Actualiza el frame1 para el próximo ciclo\n",
    "        frame1 = frame2\n",
    "\n",
    "        # Salta frames para alcanzar la frecuencia deseada\n",
    "        saltos = int(fps / fps_deseado)\n",
    "        for _ in range(saltos - 1):\n",
    "            cap.read()\n",
    "\n",
    "    # Libera los objetos de captura y escritura de video\n",
    "    cap.release()\n",
    "    out_G.release()\n",
    "    out_resultado.release()\n",
    "\n",
    "    print(f\"Video procesado y guardado en {output_video_path}.\")\n",
    "\n",
    "# Ruta del video de entrada\n",
    "video_path = 'esquina.mp4'  # Reemplaza con la ruta de tu video\n",
    "\n",
    "# Ruta del video de salida\n",
    "output_video_path = 'resultadoEsquina.mp4'\n",
    "output_video_path_Gradient = 'resultadoGradientEsquina.mp4'\n",
    "\n",
    "# Llama a la función principal para procesar los frames y guardar el nuevo video\n",
    "main(video_path, output_video_path_Gradient, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def resize_and_add_margin(input_folder, output_folder, target_size, final_size):\n",
    "    # Asegúrate de que la carpeta de salida exista\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Recorre todas las imágenes en la carpeta de entrada\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Puedes agregar más extensiones según sea necesario\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Lee la imagen\n",
    "            img = cv2.imread(input_path)\n",
    "\n",
    "            # Obtiene las dimensiones de la imagen original\n",
    "            height, width, _ = img.shape\n",
    "\n",
    "            # Calcula el tamaño de la imagen objetivo\n",
    "            new_size = max(height, width)\n",
    "            target_shape = (new_size, new_size)\n",
    "\n",
    "            # Calcula la posición del área de la imagen en el lienzo negro\n",
    "            y_pos = (new_size - height) // 2\n",
    "            x_pos = (new_size - width) // 2\n",
    "\n",
    "            # Crea un lienzo negro del tamaño objetivo\n",
    "            canvas = np.zeros((new_size, new_size, 3), dtype=np.uint8)\n",
    "\n",
    "            # Copia la imagen original en el lienzo negro en la posición calculada\n",
    "            canvas[y_pos:y_pos+height, x_pos:x_pos+width, :] = img\n",
    "\n",
    "            # Redimensiona la imagen resultante al tamaño final\n",
    "            resized_img = cv2.resize(canvas, (final_size, final_size))\n",
    "            \n",
    "            # Guarda la imagen resultante en la carpeta de salida\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            cv2.imwrite(output_path, resized_img)\n",
    "\n",
    "# Define las carpetas de entrada y salida, y el tamaño objetivo\n",
    "input_folder = 'tokio'\n",
    "output_folder = 'tokioresize'\n",
    "target_size = 512  # Puedes ajustar el tamaño deseado\n",
    "final_size = 256\n",
    "# Llama a la función para redimensionar y agregar márgenes a las imágenes\n",
    "resize_and_add_margin(input_folder, output_folder, target_size, final_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
